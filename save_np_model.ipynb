{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "import pandas as pd\n",
    "\n",
    "# Setup MySQL connection\n",
    "db = mysql.connector.connect(\n",
    "    host=\"192.168.0.120\",\n",
    "    user=\"root\",\n",
    "    passwd=\"Dbnis3258!@#$\",\n",
    "    database=\"nita\"\n",
    ")\n",
    "\n",
    "# Create a cursor (an instance of MySQLCursor class)\n",
    "cursor = db.cursor()\n",
    "\n",
    "# Execute SQL query\n",
    "cursor.execute(\"SELECT * FROM Seongju_반입량_processed\")\n",
    "\n",
    "# Fetch all the rows\n",
    "data = cursor.fetchall()\n",
    "\n",
    "# Create dataframe from data\n",
    "df = pd.DataFrame(data, columns=[i[0] for i in cursor.description])\n",
    "\n",
    "cursor.close()\n",
    "db.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#train test split\n",
    "cutoff = \"2023-01-01\" #데이터 분할 기준\n",
    "train = df[df['ds']<cutoff]\n",
    "validate = df[df['ds']>=cutoff]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split\n",
    "cutoff = \"2022-01-01\" #데이터 분할 기준\n",
    "train = df[df['ds']<cutoff]\n",
    "validate = df[df['ds']>=cutoff]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency D corresponds to 99.966% of the data.\n",
      "INFO - (NP.df_utils._infer_frequency) - Defined frequency is equal to major frequency - D\n",
      "INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/pytorch_lightning/trainer/configuration_validator.py:108: PossibleUserWarning: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "  rank_zero_warn(\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "2023-05-27 01:59:20.849379: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-27 01:59:22.703777: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200: 100%|██████████| 200/200 [00:01<00:00, 184.44it/s, loss=0.00501, v_num=45, MAE=6.81e+4, RMSE=1.04e+5, Loss=0.00498, RegLoss=0.000]  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency D corresponds to 99.966% of the data.\n",
      "INFO - (NP.df_utils._infer_frequency) - Defined frequency is equal to major frequency - D\n",
      "INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 32\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/pytorch_lightning/trainer/configuration_validator.py:108: PossibleUserWarning: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "  rank_zero_warn(\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200: 100%|██████████| 200/200 [00:01<00:00, 177.44it/s, loss=0.00613, v_num=46, MAE=4.85e+4, RMSE=8.12e+4, Loss=0.00648, RegLoss=0.000]  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency D corresponds to 99.966% of the data.\n",
      "INFO - (NP.df_utils._infer_frequency) - Defined frequency is equal to major frequency - D\n",
      "INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 32\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/pytorch_lightning/trainer/configuration_validator.py:108: PossibleUserWarning: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "  rank_zero_warn(\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200: 100%|██████████| 200/200 [00:01<00:00, 173.67it/s, loss=0.00644, v_num=47, MAE=4.57e+4, RMSE=7.75e+4, Loss=0.0058, RegLoss=0.000]   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency D corresponds to 99.966% of the data.\n",
      "INFO - (NP.df_utils._infer_frequency) - Defined frequency is equal to major frequency - D\n",
      "INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 32\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/pytorch_lightning/trainer/configuration_validator.py:108: PossibleUserWarning: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "  rank_zero_warn(\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200: 100%|██████████| 200/200 [00:01<00:00, 176.94it/s, loss=0.00686, v_num=48, MAE=4.85e+4, RMSE=8.06e+4, Loss=0.0064, RegLoss=0.000]    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency D corresponds to 99.966% of the data.\n",
      "INFO - (NP.df_utils._infer_frequency) - Defined frequency is equal to major frequency - D\n",
      "INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 32\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/pytorch_lightning/trainer/configuration_validator.py:108: PossibleUserWarning: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "  rank_zero_warn(\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200: 100%|██████████| 200/200 [00:01<00:00, 174.59it/s, loss=0.00495, v_num=49, MAE=4.51e+4, RMSE=7.56e+4, Loss=0.00568, RegLoss=0.000]  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from neuralprophet import NeuralProphet\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from neuralprophet import save, load\n",
    "\n",
    "\n",
    "# Define base Neural Prophet models with different configurations\n",
    "models = [\n",
    "NeuralProphet(\n",
    "    growth='linear',\n",
    "    n_lags=8, \n",
    "    n_forecasts=30*12,\n",
    "    seasonality_mode='additive',\n",
    "    n_changepoints=50,\n",
    "    # num_hidden_layers=3,\n",
    "    weekly_seasonality='auto',\n",
    "    yearly_seasonality=True, \n",
    "    daily_seasonality=False, \n",
    "    normalize='minmax',\n",
    "    # d_hidden=64, \n",
    "    learning_rate=0.03,\n",
    "    batch_size=45,\n",
    "    ),\n",
    "    NeuralProphet(n_lags=10, learning_rate=0.001),\n",
    "    NeuralProphet(n_lags=20, learning_rate=0.001),\n",
    "    NeuralProphet(n_lags=10, learning_rate=0.01),\n",
    "    NeuralProphet(n_lags=20, learning_rate=0.01),\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# Train the base models\n",
    "for i, model in enumerate(models):\n",
    "     # Update the progress bar with each iteration\n",
    "\n",
    "    model.fit(train, freq='D', epochs=200)\n",
    "    save(model, f\"saved_model_{i}.np\") \n",
    "\n",
    "    \n",
    "# Complete the progress bar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []  # An empty list to store the loaded models\n",
    "\n",
    "for i in range(5):  # 'number_of_models' should be replaced with the number of models you have saved\n",
    "    model = load(f\"saved_model_{i}.np\")  # Load the model from the file\n",
    "    models.append(model)  # Add the loaded model to the list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<neuralprophet.forecaster.NeuralProphet at 0x7f4e99d76140>,\n",
       " <neuralprophet.forecaster.NeuralProphet at 0x7f4e51715d50>,\n",
       " <neuralprophet.forecaster.NeuralProphet at 0x7f4e629d09d0>,\n",
       " <neuralprophet.forecaster.NeuralProphet at 0x7f4e510e7d90>,\n",
       " <neuralprophet.forecaster.NeuralProphet at 0x7f4e517aad40>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.df_utils._infer_frequency) - Major frequency D corresponds to 99.726% of the data.\n",
      "INFO - (NP.df_utils._infer_frequency) - Defined frequency is equal to major frequency - D\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency D corresponds to 99.862% of the data.\n",
      "INFO - (NP.df_utils._infer_frequency) - Defined frequency is equal to major frequency - D\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 10.55it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency D corresponds to 99.726% of the data.\n",
      "INFO - (NP.df_utils._infer_frequency) - Defined frequency is equal to major frequency - D\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency D corresponds to 99.727% of the data.\n",
      "INFO - (NP.df_utils._infer_frequency) - Defined frequency is equal to major frequency - D\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 121.39it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency D corresponds to 99.726% of the data.\n",
      "INFO - (NP.df_utils._infer_frequency) - Defined frequency is equal to major frequency - D\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency D corresponds to 99.727% of the data.\n",
      "INFO - (NP.df_utils._infer_frequency) - Defined frequency is equal to major frequency - D\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 108.08it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency D corresponds to 99.726% of the data.\n",
      "INFO - (NP.df_utils._infer_frequency) - Defined frequency is equal to major frequency - D\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency D corresponds to 99.727% of the data.\n",
      "INFO - (NP.df_utils._infer_frequency) - Defined frequency is equal to major frequency - D\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 117.41it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency D corresponds to 99.726% of the data.\n",
      "INFO - (NP.df_utils._infer_frequency) - Defined frequency is equal to major frequency - D\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency D corresponds to 99.727% of the data.\n",
      "INFO - (NP.df_utils._infer_frequency) - Defined frequency is equal to major frequency - D\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 40.10it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "errors = []\n",
    "for model in models:\n",
    "    forecast = model.predict(validate)\n",
    "    forecast['yhat1'].fillna(0,inplace=True)\n",
    "    error = mean_squared_error(validate['y'], forecast['yhat1'])\n",
    "    errors.append(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6752108907.123243,\n",
       " 6675054501.922746,\n",
       " 5406525059.531014,\n",
       " 6669522442.907918,\n",
       " 5363402719.707516]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre: [1.48101877e-10 1.49811511e-10 1.84961688e-10 1.49935773e-10\n",
      " 1.86448800e-10]\n",
      "after: [0.18077526 0.18286206 0.22576687 0.18301374 0.22758206]\n"
     ]
    }
   ],
   "source": [
    "weights = 1 / np.array(errors)\n",
    "print(\"pre:\",weights)\n",
    "weights = weights / np.sum(weights)  # Normalize the weights\n",
    "print(\"after:\",weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "ensemble_forecast = np.zeros_like(validate['y'].values)\n",
    "print(ensemble_forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.df_utils._infer_frequency) - Major frequency D corresponds to 99.726% of the data.\n",
      "INFO - (NP.df_utils._infer_frequency) - Defined frequency is equal to major frequency - D\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency D corresponds to 99.862% of the data.\n",
      "INFO - (NP.df_utils._infer_frequency) - Defined frequency is equal to major frequency - D\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  5.65it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/neuralprophet/data/process.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_forecast[name] = yhat\n",
      "INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency D corresponds to 99.726% of the data.\n",
      "INFO - (NP.df_utils._infer_frequency) - Defined frequency is equal to major frequency - D\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency D corresponds to 99.727% of the data.\n",
      "INFO - (NP.df_utils._infer_frequency) - Defined frequency is equal to major frequency - D\n",
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 118.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency D corresponds to 99.726% of the data.\n",
      "INFO - (NP.df_utils._infer_frequency) - Defined frequency is equal to major frequency - D\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency D corresponds to 99.727% of the data.\n",
      "INFO - (NP.df_utils._infer_frequency) - Defined frequency is equal to major frequency - D\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 114.30it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency D corresponds to 99.726% of the data.\n",
      "INFO - (NP.df_utils._infer_frequency) - Defined frequency is equal to major frequency - D\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency D corresponds to 99.727% of the data.\n",
      "INFO - (NP.df_utils._infer_frequency) - Defined frequency is equal to major frequency - D\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 118.69it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency D corresponds to 99.726% of the data.\n",
      "INFO - (NP.df_utils._infer_frequency) - Defined frequency is equal to major frequency - D\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency D corresponds to 99.727% of the data.\n",
      "INFO - (NP.df_utils._infer_frequency) - Defined frequency is equal to major frequency - D\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hadoop/anaconda3/envs/graph/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 117.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Ensemble model: weighted average of the base models\n",
    "for model, weight in zip(models, weights):\n",
    "    forecast = model.predict(validate)\n",
    "    forecast['yhat1'].fillna(0,inplace=True)\n",
    "\n",
    "    ensemble_forecast += weight * forecast['yhat1'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble mean absolute error: 36900.39\n",
      "Ensemble root mean squared error: 76447.4\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the ensemble model\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
    "\n",
    "ensemble_error = mean_absolute_error(validate['y'], ensemble_forecast)\n",
    "rms_error = np.sqrt(mean_squared_error(validate['y'], ensemble_forecast))\n",
    "\n",
    "\n",
    "rounded_ensemble_error = round(ensemble_error, 2)\n",
    "rounded_rms_error = round(rms_error, 2)\n",
    "\n",
    "print(\"Ensemble mean absolute error:\", rounded_ensemble_error)\n",
    "print(\"Ensemble root mean squared error:\", rounded_rms_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame()\n",
    "test_df['y'] = validate['y']\n",
    "test_df['yhat'] = ensemble_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2538</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2539</th>\n",
       "      <td>2022-01-02</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2540</th>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2541</th>\n",
       "      <td>2022-01-04</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2542</th>\n",
       "      <td>2022-01-05</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2898</th>\n",
       "      <td>2022-12-27</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2899</th>\n",
       "      <td>2022-12-28</td>\n",
       "      <td>130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2900</th>\n",
       "      <td>2022-12-29</td>\n",
       "      <td>340.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2901</th>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2902</th>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>935.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>365 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ds      y\n",
       "2538 2022-01-01    0.0\n",
       "2539 2022-01-02    0.0\n",
       "2540 2022-01-03    0.0\n",
       "2541 2022-01-04    0.0\n",
       "2542 2022-01-05    0.0\n",
       "...         ...    ...\n",
       "2898 2022-12-27    0.0\n",
       "2899 2022-12-28  130.0\n",
       "2900 2022-12-29  340.0\n",
       "2901 2022-12-30    0.0\n",
       "2902 2022-12-31  935.0\n",
       "\n",
       "[365 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>yhat</th>\n",
       "      <th>ds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2538</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2022-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2539</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2022-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2540</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2022-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2541</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2022-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2542</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2022-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2898</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6780.020107</td>\n",
       "      <td>2022-12-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2899</th>\n",
       "      <td>130.0</td>\n",
       "      <td>6704.864073</td>\n",
       "      <td>2022-12-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2900</th>\n",
       "      <td>340.0</td>\n",
       "      <td>10254.249835</td>\n",
       "      <td>2022-12-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2901</th>\n",
       "      <td>0.0</td>\n",
       "      <td>14922.005258</td>\n",
       "      <td>2022-12-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2902</th>\n",
       "      <td>935.0</td>\n",
       "      <td>7673.830216</td>\n",
       "      <td>2022-12-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>365 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          y          yhat         ds\n",
       "2538    0.0      0.000000 2022-01-01\n",
       "2539    0.0      0.000000 2022-01-02\n",
       "2540    0.0      0.000000 2022-01-03\n",
       "2541    0.0      0.000000 2022-01-04\n",
       "2542    0.0      0.000000 2022-01-05\n",
       "...     ...           ...        ...\n",
       "2898    0.0   6780.020107 2022-12-27\n",
       "2899  130.0   6704.864073 2022-12-28\n",
       "2900  340.0  10254.249835 2022-12-29\n",
       "2901    0.0  14922.005258 2022-12-30\n",
       "2902  935.0   7673.830216 2022-12-31\n",
       "\n",
       "[365 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['ds'] = validate['ds']\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Please install ipywidgets>=7.0.0 to use the FigureWidget class",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 17\u001b[0m\n\u001b[1;32m      7\u001b[0m new \u001b[39m=\u001b[39m [trace_y, trace_yhat1]\n\u001b[1;32m      9\u001b[0m layout \u001b[39m=\u001b[39m go\u001b[39m.\u001b[39mLayout(\n\u001b[1;32m     10\u001b[0m     title\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mForecast Plot\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     11\u001b[0m     xaxis\u001b[39m=\u001b[39m\u001b[39mdict\u001b[39m(title\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mIndex\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m     height\u001b[39m=\u001b[39m\u001b[39m500\u001b[39m,\n\u001b[1;32m     15\u001b[0m )\n\u001b[0;32m---> 17\u001b[0m fig \u001b[39m=\u001b[39m go\u001b[39m.\u001b[39;49mFigure(data\u001b[39m=\u001b[39;49mnew, layout\u001b[39m=\u001b[39;49mlayout)\n\u001b[1;32m     18\u001b[0m fig\u001b[39m.\u001b[39mshow()\n",
      "File \u001b[0;32m~/anaconda3/envs/graph/lib/python3.10/site-packages/plotly_resampler/registering.py:76\u001b[0m, in \u001b[0;36m_register_wrapper.<locals>.wrapped_constr\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[39m@wraps\u001b[39m(constr)\n\u001b[1;32m     74\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_constr\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     75\u001b[0m     \u001b[39m# print(f\"Executing constructor wrapper for {constr_name}\", constr)\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m     \u001b[39mreturn\u001b[39;00m pr_class(constr(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49maggregator_kwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/graph/lib/python3.10/site-packages/plotly_resampler/figure_resampler/figurewidget_resampler.py:56\u001b[0m, in \u001b[0;36mFigureWidgetResampler.__init__\u001b[0;34m(self, figure, convert_existing_traces, default_n_shown_samples, default_downsampler, resampled_trace_prefix_suffix, show_mean_aggregation_size, convert_traces_kwargs, verbose)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[1;32m     42\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m     43\u001b[0m     figure: BaseFigure \u001b[39m|\u001b[39m \u001b[39mdict\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     54\u001b[0m ):\n\u001b[1;32m     55\u001b[0m     \u001b[39m# Parse the figure input before calling `super`\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m     f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_figure_class(go\u001b[39m.\u001b[39;49mFigureWidget)()\n\u001b[1;32m     57\u001b[0m     f\u001b[39m.\u001b[39m_data_validator\u001b[39m.\u001b[39mset_uid \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m     59\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(figure, BaseFigure):\n\u001b[1;32m     60\u001b[0m         \u001b[39m# A base figure object, can be;\u001b[39;00m\n\u001b[1;32m     61\u001b[0m         \u001b[39m# - a base plotly figure: go.Figure or go.FigureWidget\u001b[39;00m\n\u001b[1;32m     62\u001b[0m         \u001b[39m# - a plotly-resampler figure: subclass of AbstractFigureAggregator\u001b[39;00m\n\u001b[1;32m     63\u001b[0m         \u001b[39m# => we first copy the layout, grid_str and grid ref\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/graph/lib/python3.10/site-packages/plotly/missing_ipywidgets.py:13\u001b[0m, in \u001b[0;36mFigureWidget.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m---> 13\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\n\u001b[1;32m     14\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPlease install ipywidgets>=7.0.0 to use the FigureWidget class\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     15\u001b[0m     )\n",
      "\u001b[0;31mImportError\u001b[0m: Please install ipywidgets>=7.0.0 to use the FigureWidget class"
     ]
    }
   ],
   "source": [
    "import plotly.graph_objs as go\n",
    "\n",
    "# Assume 'forecast' is your pandas DataFrame with columns 'y' and 'yhat1'\n",
    "trace_y = go.Scatter(x=test_df.ds, y=test_df['y'], mode='lines', name='y')\n",
    "trace_yhat1 = go.Scatter(x=test_df.ds, y=test_df['yhat'], mode='lines', name='yhat1')\n",
    "\n",
    "new = [trace_y, trace_yhat1]\n",
    "\n",
    "layout = go.Layout(\n",
    "    title='Forecast Plot',\n",
    "    xaxis=dict(title='Index'),\n",
    "    yaxis=dict(title='Value'),\n",
    "    width=1000,\n",
    "    height=500,\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=new, layout=layout)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
